{"cells":[{"cell_type":"markdown","source":["2. Pipeline: All the transformation following the CRISP-DM methodology."],"metadata":{"id":"-qnrAW0yDGdT"}},{"cell_type":"code","source":["# if you are using a google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir('/content/drive/My Drive/Berkeley/Unit11/practical_application_II')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ur-sy5ri5Fet","executionInfo":{"status":"ok","timestamp":1739837984175,"user_tz":480,"elapsed":30862,"user":{"displayName":"Paul Rivera","userId":"16279685022766326275"}},"outputId":"e69c0ffe-5f2e-4096-e966-0efe12eae854"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import datetime\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import FunctionTransformer, StandardScaler\n","from sklearn.compose import ColumnTransformer\n","\n","# Because I got Session Crashed after using all available RAM\n","# I decided to drop the column VIN ( I don't think the VIN number has any relevant importance predicting the price )\n","# and used dtype_dict\n","dtype_dict = {\n","    'price': 'int32',\n","    'year': 'float32',\n","    'odometer': 'float32'\n","}\n","cars = pd.read_csv('data/vehicles.csv', dtype=dtype_dict)\n","cars.drop(columns=['VIN'], inplace=True)\n","\n","# and take  a random 50% of the total rows of the dataset\n","cars_sample = cars.sample(frac=0.5, random_state=42)\n","\n","numerical_cols = ['price', 'year', 'odometer']  # Before log transformation\n","# Build a ColumnTransformer\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', StandardScaler(), numerical_cols),\n","        # I could add more and more transformers for categorical variables here as needed,but no time :-)\n","    ],\n","    remainder='passthrough'\n",")\n","\n","\n","# ========= Step 1: Outlier Detection and Removal =========\n","def remove_outliers_iqr(df, numeric_cols=['price', 'year', 'odometer'], factor=1.5):\n","    \"\"\"\n","    Removing those rows from the numeroc colums with outlier values using the IQR method.\n","\n","    Parameters:\n","      df (pd.DataFrame): Input DataFrame.\n","      numeric_cols (list): List of numeric columns to check.\n","      factor (float): Multiplier for the IQR to define outlier thresholds.\n","\n","    Returns:\n","      pd.DataFrame: DataFrame with outliers removed.\n","    \"\"\"\n","    df = df.copy()\n","    for col in numeric_cols:\n","        Q1 = df[col].quantile(0.25)\n","        Q3 = df[col].quantile(0.75)\n","        IQR = Q3 - Q1\n","        lower_bound = Q1 - factor * IQR\n","        upper_bound = Q3 + factor * IQR\n","        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n","    return df\n","\n","# ========= Step 2: Missing Value Imputation =========\n","def impute_missing_values(df):\n","    df = df.copy()\n","    # For numeric columns, fill missing values with the median\n","    numeric_cols = ['year', 'odometer', 'price']\n","    for col in numeric_cols:\n","        df[col] = df[col].fillna(df[col].median())\n","\n","    # For categorical columns, fill missing values with 'Unknown'\n","    # Not considering state .. I don't think the state could make any difference\n","    categorical_cols = ['region', 'manufacturer', 'model', 'condition',\n","                        'cylinders', 'fuel', 'title_status', 'transmission',\n","                        'drive', 'size', 'type', 'paint_color']\n","    for col in categorical_cols:\n","        df[col] = df[col].fillna('Unknown')\n","        df['year'] = df['year'].astype('int32')\n","\n","    return df\n","\n","# ========= Step 3: Outlier Treatment and Odometer Transformation =========\n","def process_odometer(df):\n","    df = df.copy()\n","    # Cap the odometer values at the 1st and 99th percentiles\n","    lower_bound = df['odometer'].quantile(0.01)\n","    upper_bound = df['odometer'].quantile(0.99)\n","    df['odometer_capped'] = df['odometer'].clip(lower=lower_bound, upper=upper_bound)\n","\n","    # Log-transform the capped odometer to reduce right skewness (use log1p to handle zero values)\n","    df['odometer_log'] = np.log1p(df['odometer_capped'])\n","    return df\n","\n","# ========= Step 4: Feature Engineering =========\n","def feature_engineering(df):\n","    df = df.copy()\n","    # Create a new feature: car age (current year - production year)\n","    current_year = datetime.datetime.now().year\n","    df['age'] = current_year - df['year'].astype(int)\n","\n","    # Create price per mile; avoid division by zero by replacing zero with NaN first\n","    # instead of remove the whole row to preserv potential valid data. Like new vehicles.\n","    # can introduce some bias in my analysis...\n","    # Create price per mile; handle potential division by zero by filling with NaN first\n","    df['price_per_mile'] = df['price'] / df['odometer']\n","    # Replace inf with NaN\n","    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n","    # Fill NaN values with median of price_per_mile column\n","    df['price_per_mile'].fillna(df['price_per_mile'].median(), inplace=True)\n","\n","    return df\n","\n","# ========= Step 5: Reduce Categories for Manufacturer =========\n","def reduce_manufacturer(df, threshold=0.01):\n","  # I tested several values for the threshold starting with 0.05, I realized 0.01 gives me fair list of\n","  # manufacturers. O.05 only gaveme Toyota Chevrolet and Ford\n","    df = df.copy()\n","    # Calculate the relative frequency of each manufacturer\n","    freq = df['manufacturer'].value_counts(normalize=True)\n","    # Identify manufacturers that represent at least 'threshold' of observations\n","    frequent = freq[freq >= threshold].index\n","    # Create a new column where infrequent manufacturers are replaced with 'Other'\n","    df['manufacturer_reduced'] = df['manufacturer'].apply(\n","        lambda x: x if x in frequent else 'Other'\n","    )\n","    return df\n","\n","# ========= Step 6: Ordinal Encoding =========\n","def ordinal_encoding(df):\n","    df = df.copy()\n","    # Based in previous analysis These are the ordinal mappings..\n","    condition_mapping = {\n","        'salvage': 1,\n","        'fair': 2,\n","        'good': 3,\n","        'excellent': 4,\n","        'like new': 5,\n","        'new': 6,\n","        'Unknown': np.nan\n","    }\n","    title_status_mapping = {\n","        'salvage': 1,\n","        'rebuilt': 2,\n","        'clean': 3,\n","        'Unknown': np.nan\n","    }\n","    size_mapping = {\n","        'compact': 1,\n","        'midsize': 2,\n","        'fullsize': 3,\n","        'Unknown': np.nan\n","    }\n","\n","    df['condition_ordinal'] = df['condition'].map(condition_mapping)\n","    df['title_status_ordinal'] = df['title_status'].map(title_status_mapping)\n","    df['size_ordinal'] = df['size'].map(size_mapping)\n","\n","    return df\n","\n","# ========= Step 7: One-Hot Encoding for Remaining Categorical Variables =========\n","def one_hot_encoding(df):\n","    df = df.copy()\n","    # List the remaining categorical columns to one-hot encode.\n","    # Exclude columns that have already been ordinal-encoded or transformed.\n","    cols_to_encode = ['manufacturer', 'cylinders', 'fuel',\n","                      'transmission']\n","    df = pd.get_dummies(df, columns=cols_to_encode, drop_first=True)\n","    return df\n","\n","# ========= Full Preprocessing Function =========\n","def full_preprocessing(df):\n","\n","    # Step 0: Apply ColumnTransformer for scaling (NEW STEP)\n","    df_transformed = preprocessor.fit_transform(df) # return a numpy array\n","    # ----> Convert back to DataFrame (important!)\n","    remainder_columns = [col for col in df.columns if col not in numerical_cols]\n","    all_columns = numerical_cols + remainder_columns\n","    df = pd.DataFrame(df_transformed, columns=all_columns)\n","\n","    df = pd.DataFrame(df, columns=numerical_cols + list(df.columns[len(numerical_cols):]))\n","    # Step 1: Remove outliers using the IQR method\n","    df = remove_outliers_iqr(df, numeric_cols = numerical_cols, factor=1.5)\n","    # Step 2: Impute missing values\n","    df = impute_missing_values(df)\n","    # Step 3: Process the odometer variable (cap and log-transform)\n","    df = process_odometer(df)\n","    # Step 4: Create additional features (age, price per mile)\n","    df = feature_engineering(df)\n","    # Step 5: Reduce manufacturer categories\n","    df = reduce_manufacturer(df)\n","    # Step 6: Apply ordinal encoding on select columns\n","    df = ordinal_encoding(df)\n","    # Step 7: One-hot encode the remaining categorical variables\n","    df = one_hot_encoding(df)\n","    return df\n","\n","# ========= Create the Pipeline =========\n","preprocessing_pipeline = Pipeline(steps=[\n","    ('full_preprocessing', FunctionTransformer(full_preprocessing))\n","])\n","\n","# ========= Apply the Pipeline =========\n","# need to load the sample 50% to avoid memory RAM exhausting\n","# cars = pd.read_csv('data/vehicles.csv')\n","\n","# Run the full preprocessing pipeline with the 50% of the full date set to avoid memory issues\n","cars_preprocessed = preprocessing_pipeline.transform(cars_sample)\n","\n","# Display the first few rows of the preprocessed data\n","print(cars_preprocessed.head())\n","\n"],"metadata":{"id":"6DgK2cwz5YGx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739850014891,"user_tz":480,"elapsed":5852,"user":{"displayName":"Paul Rivera","userId":"16279685022766326275"}},"outputId":"f1576bc4-719e-4119-9bf2-d8564ac22faf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-16-939525ec2d46>:62: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  df[col] = df[col].fillna(df[col].median())\n","<ipython-input-16-939525ec2d46>:62: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  df[col] = df[col].fillna(df[col].median())\n","<ipython-input-16-939525ec2d46>:62: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  df[col] = df[col].fillna(df[col].median())\n","<ipython-input-16-939525ec2d46>:100: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  df.replace([np.inf, -np.inf], np.nan, inplace=True)\n","<ipython-input-16-939525ec2d46>:102: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df['price_per_mile'].fillna(df['price_per_mile'].median(), inplace=True)\n"]},{"output_type":"stream","name":"stdout","text":["      price  year  odometer          id                  region  \\\n","0  0.003609     0 -0.270731  7315883828                lakeland   \n","3 -0.000587     0 -0.024469  7312663807      northern panhandle   \n","4 -0.003020     0 -0.230290  7315368523                  eugene   \n","5 -0.002642     0  0.586199  7309863303  waterloo / cedar falls   \n","6 -0.000351     0 -0.277230  7315163492                 jackson   \n","\n","                   model  condition title_status    drive     size  ...  \\\n","0  f150 super cab lariat       good        clean      4wd  Unknown  ...   \n","3                   328i    Unknown        clean  Unknown  Unknown  ...   \n","4            suburban ls    Unknown        clean  Unknown  Unknown  ...   \n","5           town country  excellent        clean      fwd  Unknown  ...   \n","6        outlander sport  excellent        clean      fwd  Unknown  ...   \n","\n","  cylinders_Unknown cylinders_other fuel_diesel  fuel_electric  fuel_gas  \\\n","0             False           False       False          False      True   \n","3              True           False       False          False      True   \n","4             False           False       False          False     False   \n","5             False           False       False          False      True   \n","6             False           False       False          False      True   \n","\n","   fuel_hybrid  fuel_other transmission_automatic  transmission_manual  \\\n","0        False       False                  False                False   \n","3        False       False                   True                False   \n","4        False        True                   True                False   \n","5        False       False                   True                False   \n","6        False       False                   True                False   \n","\n","   transmission_other  \n","0                True  \n","3               False  \n","4               False  \n","5               False  \n","6               False  \n","\n","[5 rows x 78 columns]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# Now I need to create training data set and test dataset\n","# Separate features (X) and target (y)\n","X = cars_preprocessed.drop(\"price\", axis=1)\n","y = cars_preprocessed[\"price\"]\n","\n","# Split the data: 80% training, 20% testing (adjust test_size as needed)\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","# Optionally, print the shapes to verify the split\n","print(\"Training set shape:\", X_train.shape, y_train.shape)\n","print(\"Testing set shape:\", X_test.shape, y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5IWJa-zXT_U8","executionInfo":{"status":"ok","timestamp":1739839167637,"user_tz":480,"elapsed":152,"user":{"displayName":"Paul Rivera","userId":"16279685022766326275"}},"outputId":"b251c638-d108-4c0e-a584-2751b29c8f65"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set shape: (157738, 77) (157738,)\n","Testing set shape: (39435, 77) (39435,)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AggDm79KSrMd"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yT-qzQSGSrMd"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PqBl5E5dSrMd"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NE1OSUn9SrMd"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vn_IOiyWSrMd"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-TZZ9JcVSrMd"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BBY9vTbBSrMd"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[{"file_id":"1jCcBlOvQYDxvdIqFUWPpu1qI4scapAhX","timestamp":1740030379560},{"file_id":"1L5jQkraVEGX4Rqg8-CidH6lDCk6PXetX","timestamp":1738636979539}]}},"nbformat":4,"nbformat_minor":0}